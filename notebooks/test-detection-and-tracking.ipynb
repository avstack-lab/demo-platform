{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4e5e32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, sys, glob\n",
    "from tqdm import tqdm\n",
    "import avstack\n",
    "import avapi\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data_dir = '../data/MOT15/'\n",
    "\n",
    "MSM = avapi.mot15.MOT15SceneManager(data_dir=data_dir)\n",
    "MSD = MSM.get_scene_dataset_by_name('ADL-Rundle-6')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901c8b7b",
   "metadata": {},
   "source": [
    "## Run Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c37af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /home/spencer/Documents/Projects/AVstack/platforms/demo-platform/third_party/lib-avstack-core/third_party/mmdetection/checkpoints/coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\n"
     ]
    }
   ],
   "source": [
    "framerate = 30.0\n",
    "detector = avstack.modules.perception.object2dfv.MMDetObjectDetector2D(\n",
    "    model='fasterrcnn', dataset='coco-person', deploy=False)\n",
    "tracker = avstack.modules.tracking.tracker2d.SortTracker2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64fc5cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███▊                                                     | 2/30 [00:00<00:10,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 elements at frame 391, time 13.0, ID: \n",
      "[]\n",
      "0 elements at frame 392, time 13.033333333333333, ID: \n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████▌                                                 | 4/30 [00:01<00:06,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 elements at frame 393, time 13.066666666666666, ID: \n",
      "[]\n",
      "0 elements at frame 394, time 13.1, ID: \n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████▍                                             | 6/30 [00:01<00:04,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 elements at frame 395, time 13.133333333333333, ID: \n",
      "[]\n",
      "0 elements at frame 396, time 13.166666666666666, ID: \n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████▎                                           | 7/30 [00:01<00:05,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 elements at frame 397, time 13.2, ID: \n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m img \u001b[38;5;241m=\u001b[39m MSD\u001b[38;5;241m.\u001b[39mget_image(frame\u001b[38;5;241m=\u001b[39mframe)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# -- run detections and tracking\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m dets \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(dets)\n\u001b[1;32m     17\u001b[0m tracks \u001b[38;5;241m=\u001b[39m tracker(detections\u001b[38;5;241m=\u001b[39mdets, frame\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mframe, t\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mtimestamp, platform\u001b[38;5;241m=\u001b[39mego_ref)\n",
      "File \u001b[0;32m~/Documents/Projects/AVstack/platforms/demo-platform/third_party/lib-avstack-core/avstack/modules/perception/base.py:37\u001b[0m, in \u001b[0;36m_PerceptionAlgorithm.__call__\u001b[0;34m(self, data, frame, identifier, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m     detections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midentifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave:\n\u001b[1;32m     41\u001b[0m         fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%06i\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m frame)\n",
      "File \u001b[0;32m~/Documents/Projects/AVstack/platforms/demo-platform/third_party/lib-avstack-core/avstack/modules/perception/object2dfv.py:124\u001b[0m, in \u001b[0;36mMMDetObjectDetector2D._execute\u001b[0;34m(self, data, identifier, eval_method, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m img \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mrgb_image\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# -- inference\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m result_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_mm_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# -- postprocess objects\u001b[39;00m\n\u001b[1;32m    127\u001b[0m detections \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mconvert_mm2d_to_avstack(\n\u001b[1;32m    128\u001b[0m     result_,\n\u001b[1;32m    129\u001b[0m     data\u001b[38;5;241m.\u001b[39mcalibration,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeploy,\n\u001b[1;32m    136\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Projects/AVstack/platforms/demo-platform/third_party/lib-avstack-core/avstack/modules/perception/object2dfv.py:143\u001b[0m, in \u001b[0;36mMMDetObjectDetector2D.run_mm_inference\u001b[0;34m(self, image, eval_method)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_mm_from_deploy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, image)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_mm_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_detector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_method\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/AVstack/platforms/demo-platform/third_party/lib-avstack-core/avstack/modules/perception/object2dfv.py:158\u001b[0m, in \u001b[0;36mMMDetObjectDetector2D.run_mm_from_checkpoint\u001b[0;34m(inference_detector, model, image, eval_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m         result_ \u001b[38;5;241m=\u001b[39m inference_detector(model, data_file)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m eval_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     result_ \u001b[38;5;241m=\u001b[39m \u001b[43minference_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(eval_method)\n",
      "File \u001b[0;32m~/Documents/Projects/AVstack/platforms/demo-platform/third_party/lib-avstack-core/third_party/mmdetection/mmdet/apis/inference.py:170\u001b[0m, in \u001b[0;36minference_detector\u001b[0;34m(model, imgs, test_pipeline)\u001b[0m\n\u001b[1;32m    168\u001b[0m     data_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(img_path\u001b[38;5;241m=\u001b[39mimg, img_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# build the data pipeline\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m data_ \u001b[38;5;241m=\u001b[39m \u001b[43mtest_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m data_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [data_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    173\u001b[0m data_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_samples\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [data_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_samples\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/jumpstreet-KAn1Ke7K-py3.10/lib/python3.10/site-packages/mmcv/transforms/base.py:12\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m              results: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Union[Dict, Tuple[List, List]]]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/jumpstreet-KAn1Ke7K-py3.10/lib/python3.10/site-packages/mmcv/transforms/wrappers.py:88\u001b[0m, in \u001b[0;36mCompose.transform\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call function to apply transforms sequentially.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    dict or None: Transformed results.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 88\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/jumpstreet-KAn1Ke7K-py3.10/lib/python3.10/site-packages/mmcv/transforms/base.py:12\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m              results: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Union[Dict, Tuple[List, List]]]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/AVstack/platforms/demo-platform/third_party/lib-avstack-core/third_party/mmdetection/mmdet/structures/bbox/box_type.py:267\u001b[0m, in \u001b[0;36mautocast_box_type.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, results, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, results: \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt_bboxes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt_bboxes\u001b[39m\u001b[38;5;124m'\u001b[39m], BaseBoxes)):\n\u001b[0;32m--> 267\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt_bboxes\u001b[39m\u001b[38;5;124m'\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    269\u001b[0m         results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt_bboxes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m box_type_cls(\n\u001b[1;32m    270\u001b[0m             results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt_bboxes\u001b[39m\u001b[38;5;124m'\u001b[39m], clone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/Projects/AVstack/platforms/demo-platform/third_party/lib-avstack-core/third_party/mmdetection/mmdet/datasets/transforms/transforms.py:154\u001b[0m, in \u001b[0;36mResize.transform\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m    152\u001b[0m     img_shape \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    153\u001b[0m     results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m _scale_size(img_shape[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_factor)\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resize_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_bboxes(results)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_masks(results)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/jumpstreet-KAn1Ke7K-py3.10/lib/python3.10/site-packages/mmcv/transforms/processing.py:172\u001b[0m, in \u001b[0;36mResize._resize_img\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_ratio:\n\u001b[0;32m--> 172\u001b[0m         img, scale_factor \u001b[38;5;241m=\u001b[39m \u001b[43mmmcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimrescale\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;66;03m# the w_scale and h_scale has minor difference\u001b[39;00m\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;66;03m# a real fix should be done in the mmcv.imrescale in the future\u001b[39;00m\n\u001b[1;32m    180\u001b[0m         new_h, new_w \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/jumpstreet-KAn1Ke7K-py3.10/lib/python3.10/site-packages/mmcv/image/geometric.py:283\u001b[0m, in \u001b[0;36mimrescale\u001b[0;34m(img, scale, return_scale, interpolation, backend)\u001b[0m\n\u001b[1;32m    281\u001b[0m h, w \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    282\u001b[0m new_size, scale_factor \u001b[38;5;241m=\u001b[39m rescale_size((w, h), scale, return_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 283\u001b[0m rescaled_img \u001b[38;5;241m=\u001b[39m \u001b[43mimresize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_scale:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rescaled_img, scale_factor\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/jumpstreet-KAn1Ke7K-py3.10/lib/python3.10/site-packages/mmcv/image/geometric.py:116\u001b[0m, in \u001b[0;36mimresize\u001b[0;34m(img, size, return_scale, interpolation, out, backend)\u001b[0m\n\u001b[1;32m    114\u001b[0m     resized_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(pil_image)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m     resized_img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv2_interp_codes\u001b[49m\u001b[43m[\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_scale:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resized_img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_dets = {}\n",
    "all_tracks = {}\n",
    "i_frame_start = 390\n",
    "n_frames = 30; n_frames = min(len(MSD), n_frames)\n",
    "cvt_to_rgb = True\n",
    "ego_ref = MSD.get_ego_reference(frame=1)\n",
    "\n",
    "all_frames = []\n",
    "for i_frame, frame in tqdm(enumerate(MSD.frames[i_frame_start:i_frame_start+n_frames]), total=n_frames):\n",
    "    all_frames.append(frame)\n",
    "    # -- load image in avstack standard format\n",
    "    img = MSD.get_image(frame=frame)\n",
    "    \n",
    "    # -- run detections and tracking\n",
    "    dets = detector(img)\n",
    "    print(dets)\n",
    "    tracks = tracker(detections=dets, frame=img.frame, t=img.timestamp, platform=ego_ref)\n",
    "    \n",
    "    # -- save results\n",
    "    all_dets[frame] = dets\n",
    "    all_tracks[frame] = tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c056b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_frame = 10\n",
    "frame = all_frames[idx_frame]\n",
    "img = MSD.get_image(frame=frame)\n",
    "objs = MSD.get_objects(frame=frame)\n",
    "avapi.visualize.snapshot.show_image_with_boxes(img, objs, inline=True) \n",
    "avapi.visualize.snapshot.show_image_with_boxes(img, all_dets[frame], inline=True)\n",
    "avapi.visualize.snapshot.show_image_with_boxes(img, all_tracks[frame], inline=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6e06d-61ef-4bb3-a359-8a980f65744c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
